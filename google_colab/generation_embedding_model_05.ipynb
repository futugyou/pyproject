{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/futugyou/pyproject/blob/master/google_colab/generation_embedding_model_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "1piQHEu3zW6s"
   },
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "%pip install datasets\n",
    "%pip install sentence_transformers\n",
    "%pip install transformers\n",
    "%pip install torch\n",
    "%pip install tqdm\n",
    "%pip install scikit-learn\n",
    "%pip install mteb\n",
    "%pip install pandas\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjS_tUJz6Kp-"
   },
   "outputs": [],
   "source": [
    "# The code of generate-modle is almost identical to finetune-model\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, InputExample\n",
    "from datasets import load_dataset, Dataset\n",
    "from sentence_transformers import InputExample\n",
    "from sentence_transformers.dataset import DenoisingAutoEncoderDataset\n",
    "\n",
    "mnli = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(25_000))\n",
    "flat_sentences = mnli[\"premise\"], mnli[\"hypothesis\"]\n",
    "damaged_data = DenoisingAutoEncoderDataset(list(set(flat_sentences)))\n",
    "\n",
    "train_dataset = {\"damaged_sentences\": [], \"original_sentences\": []}\n",
    "for data in tqdm(damaged_data):\n",
    "    train_dataset[\"damaged_sentences\"].append(data[0])\n",
    "    train_dataset[\"original_sentences\"].append(data[1])\n",
    "    \n",
    "train_dataset = Dataset.from_dict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "val_sts = load_dataset(\"glue\", \"stsb\", split=\"validation\")\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentence1=val_sts[\"sentence1\"],\n",
    "    sentence2=val_sts[\"sentence2\"],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "\n",
    "word_embeddings = models.Transformer('bert-base-uncased')\n",
    "pooling_model = models.Pooling(word_embeddings.get_word_embedding_dimension(), \"cls\")\n",
    "mebedding_model = SentenceTransformer(modules=[word_embeddings, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import  losses\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "\n",
    "# loss function\n",
    "train_loss = losses.DenisingAutoEncoderLoss(model=mebedding_model)\n",
    "train_loss.decoder = train_loss.decoder.to(\"cuda\")\n",
    "\n",
    "# training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"tsdae_mebedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train model\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator model\n",
    "evaluator(embedding_model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
