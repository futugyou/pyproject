{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/futugyou/pyproject/blob/master/transformers_demo/cohere_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "1piQHEu3zW6s"
   },
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install tqdm\n",
    "%pip install cohere\n",
    "%pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Y0XwhKPez7gu"
   },
   "outputs": [],
   "source": [
    "# use cohere cloud api to do RAG\n",
    "import cohere\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from google.colab import userdata\n",
    "\n",
    "api_key = userdata.get(\"COHERE_API_KEY\")\n",
    "co = cohere.Client(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4glQa10whWkT"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Interstellar is a 2014 epic science fiction film directed by Christopher Nolan, who co-wrote the screenplay with his brother Jonathan Nolan. It features an ensemble cast led by Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn and Michael Caine. Set in a dystopian future where Earth is suffering from catastrophic blight and famine, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for mankind.\n",
    "\n",
    "The screenplay had its origins in a script that Jonathan had developed in 2007 and was originally set to be directed by Steven Spielberg. Theoretical physicist Kip Thorne was an executive producer and scientific consultant on the film, and wrote the tie-in book The Science of Interstellar. It was Lynda Obst's final film as producer before her death. Cinematographer Hoyte van Hoytema shot it on 35 mm film in the Panavision anamorphic format and IMAX 70 mm. Filming began in late 2013 and took place in Alberta, Klaustur, and Los Angeles. Interstellar uses extensive practical and miniature effects, and the company DNEG created additional visual effects.\n",
    "\n",
    "Interstellar premiered at the TCL Chinese Theatre on October 26, 2014, and was released in theaters in the United States on November 5, and in the United Kingdom on November 7. In the United States, it was first released on film stock, expanding to venues using digital projectors. The film received generally positive reviews from critics and was a commercial success, grossing $681 million worldwide during its initial theatrical run, and $758.6 million worldwide with subsequent releases, making it the tenth-highest-grossing film of 2014. Among its various accolades, Interstellar was nominated for five awards at the 87th Academy Awards, winning Best Visual Effects.\n",
    "\"\"\"\n",
    "\n",
    "texts = text.split(\".\")\n",
    "texts = [t.strip(\" \\n\") for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YAFUFprjh0Oe"
   },
   "outputs": [],
   "source": [
    "resposse = co.embed(texts=texts, input_type=\"search_document\").embeddings\n",
    "\n",
    "embeds = np.array(resposse)\n",
    "print(embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OjtnnxoOkmAE"
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "dim = embeds.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "print(index.is_trained)\n",
    "index.add(np.float32(embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1qBbksklBS8"
   },
   "outputs": [],
   "source": [
    "def search(query, number_of_results=3):\n",
    "    query_embed = co.embed(texts=[query], input_type=\"search_query\").embeddings[0]\n",
    "\n",
    "    distances, similar_item_ids = index.search(\n",
    "        np.float32([query_embed]), k=number_of_results\n",
    "    )\n",
    "\n",
    "    texts_np = np.array(texts)\n",
    "    results = pd.DataFrame(\n",
    "        data={\"texts\": texts_np[similar_item_ids[0]], \"distances\": distances[0]}\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFuRynPbl4xX"
   },
   "outputs": [],
   "source": [
    "query = \"how precise was the science\"\n",
    "results = search(query)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0f0wxcM6rT-L"
   },
   "outputs": [],
   "source": [
    "query = \"how precise was the science\"\n",
    "results = co.rerank(query=query, documents=texts, top_n=3, return_documents=True)\n",
    "\n",
    "for idx, result in enumerate(results.results):\n",
    "    print(idx, result.relevance_score, result.document.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DfC0RDoXt_OW"
   },
   "outputs": [],
   "source": [
    "%pip install rank-bm25\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W5ItkRAstpZp"
   },
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "import string\n",
    "\n",
    "\n",
    "def bm25_tokenizer(text):\n",
    "    tokenized_doc = []\n",
    "    for token in text.lower().split():\n",
    "        token = token.strip(string.punctuation)\n",
    "        if len(token) > 0 and token not in _stop_words.ENGLISH_STOP_WORDS:\n",
    "            tokenized_doc.append(token)\n",
    "    return tokenized_doc\n",
    "\n",
    "\n",
    "tokenized_corpus = []\n",
    "for passage in tqdm(texts):\n",
    "    tokenized_corpus.append(bm25_tokenizer(passage))\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ta2M0sHKvubZ"
   },
   "outputs": [],
   "source": [
    "def keyword_search(query, top_k=3, num_candidates=15):\n",
    "    tokenized_query = bm25_tokenizer(query)\n",
    "    doc_scores = bm25.get_scores(tokenized_query)\n",
    "    top_n = np.argpartition(doc_scores, -num_candidates)[-num_candidates:]\n",
    "    bm25_hits = [{\"corpus_id\": idx, \"score\": doc_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    for hit in bm25_hits[0:top_k]:\n",
    "        print(\n",
    "            \"\\t{:.3f}\\t{}\".format(\n",
    "                hit[\"score\"], texts[hit[\"corpus_id\"]].replace(\"\\n\", \" \")\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUfbltX9xqsx"
   },
   "outputs": [],
   "source": [
    "keyword_search(query=\"how precise was the science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3KG48fJdyY5f"
   },
   "outputs": [],
   "source": [
    "def keyword_and_rerank_search(query, top_k=3, num_candidates=10):\n",
    "    tokenized_query = bm25_tokenizer(query)\n",
    "    doc_scores = bm25.get_scores(tokenized_query)\n",
    "    top_n = np.argpartition(doc_scores, -num_candidates)[-num_candidates:]\n",
    "    bm25_hits = [{\"corpus_id\": idx, \"score\": doc_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    for hit in bm25_hits[0:top_k]:\n",
    "        print(\n",
    "            \"\\t{:.3f}\\t{}\".format(\n",
    "                hit[\"score\"], texts[hit[\"corpus_id\"]].replace(\"\\n\", \" \")\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # rerank\n",
    "    docs = [texts[hit[\"corpus_id\"]] for hit in bm25_hits]\n",
    "    reranked_results = co.rerank(\n",
    "        query=query, documents=docs, top_n=top_k, return_documents=True\n",
    "    )\n",
    "    for idx, result in enumerate(reranked_results.results):\n",
    "        print(idx, result.relevance_score, result.document.text)\n",
    "    return reranked_results.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M5LxWX9Ay57V"
   },
   "outputs": [],
   "source": [
    "keyword_and_rerank_search(query=\"how precise was the science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pa5cXHmn0Ajk"
   },
   "outputs": [],
   "source": [
    "query = \"income generated\"\n",
    "results = keyword_and_rerank_search(query)\n",
    "\n",
    "docs_dict = [{\"text\": result.document.text} for result in results]\n",
    "response = co.chat(message=query, documents=docs_dict)\n",
    "\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
