{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/futugyou/pyproject/blob/master/transformers_demo/clip_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1piQHEu3zW6s"
      },
      "outputs": [],
      "source": [
        "# Install required dependencies\n",
        "%pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "from PIL import Image\n",
        "\n",
        "puppy_path = \"https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/chapter09/images/puppy.png\"\n",
        "image = Image.open(urlopen(puppy_path)).convert(\"RGB\")\n",
        "\n",
        "caption = \"a puppy playing in the snow\""
      ],
      "metadata": {
        "id": "E4lmq7z2j6rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Y0XwhKPez7gu"
      },
      "outputs": [],
      "source": [
        "from transformers import CLIPTokenizerFast, CLIPProcessor, CLIPModel\n",
        "\n",
        "model_id = \"openai/clip-vit-base-patch32\"\n",
        "\n",
        "clip_tokenizer = CLIPTokenizerFast.from_pretrained(model_id)\n",
        "clip_processor = CLIPProcessor.from_pretrained(model_id)\n",
        "model = CLIPModel.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = clip_tokenizer(caption, return_tensors=\"pt\")\n",
        "inputs"
      ],
      "metadata": {
        "id": "dfpsLoq6jtXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clip_tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])"
      ],
      "metadata": {
        "id": "kFnuiueqioOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding\n",
        "text_embedding = model.get_text_features(**inputs)\n",
        "text_embedding.shape"
      ],
      "metadata": {
        "id": "Z6DsU5_1j_Av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_image = clip_processor(text=None, images=image, return_tensors=\"pt\")[\"pixel_values\"]\n",
        "processed_image.shape"
      ],
      "metadata": {
        "id": "MvOXYV7Kk3Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyqG_xDg0l1U"
      },
      "outputs": [],
      "source": [
        "# show image preprocessing\n",
        "%pip install numpy\n",
        "%pip install torch\n",
        "%pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "img = processed_image.squeeze(0)\n",
        "img = img.permute(*torch.arange(img.ndim - 1, -1, -1))\n",
        "img = np.einsum(\"ijk->jik\", img)\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "Kx9qxPWauMQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create image embedding\n",
        "image_embedding = model.get_image_features(processed_image)\n",
        "image_embedding.shape"
      ],
      "metadata": {
        "id": "qPnAzQ20wvUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_embedding /= text_embedding.norm(dim=-1, keepdim=True)\n",
        "image_embedding /= image_embedding.norm(dim=-1, keepdim=True)\n",
        "\n",
        "text_embedding = text_embedding.detach().cpu().numpy()\n",
        "image_embedding = image_embedding.detach().cpu().numpy()\n",
        "\n",
        "score = np.dot(text_embedding, image_embedding.T)\n",
        "score"
      ],
      "metadata": {
        "id": "JPZj12dexIm-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}